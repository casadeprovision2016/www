import cron from 'node-cron';
import { logger } from '../utils/logger';
import { createClient } from '@supabase/supabase-js';
import { redis } from '../services/cacheService';
import { format, subDays, startOfWeek, endOfWeek } from 'date-fns';

// Configura√ß√£o do Supabase
const supabaseUrl = process.env.SUPABASE_URL!;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_KEY!;
const supabase = createClient(supabaseUrl, supabaseServiceKey);

export class BackgroundJobsWorker {
  private isRunning = false;

  constructor() {
    this.setupGracefulShutdown();
  }

  async start(): Promise<void> {
    if (this.isRunning) {
      logger.warn('Worker j√° est√° rodando');
      return;
    }

    this.isRunning = true;
    logger.info('üöÄ Background Jobs Worker iniciado');

    this.setupJobs();
  }

  private setupJobs(): void {
    // Relat√≥rios di√°rios √†s 6h
    cron.schedule('0 6 * * *', async () => {
      try {
        logger.info('üìä Executando relat√≥rios di√°rios...');
        await this.generateDailyReports();
      } catch (error) {
        logger.error('Erro ao gerar relat√≥rios di√°rios:', error);
      }
    });

    // Limpeza de cache √†s 3h
    cron.schedule('0 3 * * *', async () => {
      try {
        logger.info('üßπ Limpando cache expirado...');
        await this.cleanExpiredCache();
      } catch (error) {
        logger.error('Erro ao limpar cache:', error);
      }
    });

    // Backup semanal aos domingos √†s 2h
    cron.schedule('0 2 * * 0', async () => {
      try {
        logger.info('üíæ Executando backup semanal...');
        await this.performWeeklyBackup();
      } catch (error) {
        logger.error('Erro ao executar backup:', error);
      }
    });

    // Limpeza de logs mensalmente no dia 1 √†s 1h
    cron.schedule('0 1 1 * *', async () => {
      try {
        logger.info('üóÇÔ∏è Limpando logs antigos...');
        await this.cleanOldLogs();
      } catch (error) {
        logger.error('Erro ao limpar logs:', error);
      }
    });

    // Health check a cada 5 minutos
    cron.schedule('*/5 * * * *', async () => {
      try {
        await this.healthCheck();
      } catch (error) {
        logger.error('Erro no health check:', error);
      }
    });

    // Notifica√ß√µes de anivers√°rios √†s 8h
    cron.schedule('0 8 * * *', async () => {
      try {
        logger.info('üéÇ Verificando anivers√°rios do dia...');
        await this.checkBirthdays();
      } catch (error) {
        logger.error('Erro ao verificar anivers√°rios:', error);
      }
    });

    // Sincroniza√ß√£o de dados a cada hora
    cron.schedule('0 * * * *', async () => {
      try {
        logger.info('üîÑ Sincronizando dados...');
        await this.syncData();
      } catch (error) {
        logger.error('Erro na sincroniza√ß√£o:', error);
      }
    });
  }

  private async generateDailyReports(): Promise<void> {
    const yesterday = format(subDays(new Date(), 1), 'yyyy-MM-dd');
    
    // Relat√≥rio de eventos do dia
    const { data: events, error: eventsError } = await supabase
      .from('events')
      .select('*')
      .gte('date', yesterday)
      .lt('date', format(new Date(), 'yyyy-MM-dd'));

    if (eventsError) {
      logger.error('Erro ao buscar eventos:', eventsError);
      return;
    }

    // Relat√≥rio de doa√ß√µes do dia
    const { data: donations, error: donationsError } = await supabase
      .from('donations')
      .select('amount')
      .gte('created_at', yesterday);

    if (donationsError) {
      logger.error('Erro ao buscar doa√ß√µes:', donationsError);
      return;
    }

    const totalDonations = donations?.reduce((sum, d) => sum + (d.amount || 0), 0) || 0;

    logger.info(`üìä Relat√≥rio di√°rio: ${events?.length || 0} eventos, R$ ${totalDonations} em doa√ß√µes`);

    // Salvar relat√≥rio no cache para consulta r√°pida
    await redis.setex(`daily_report:${yesterday}`, 86400 * 7, JSON.stringify({
      date: yesterday,
      events: events?.length || 0,
      totalDonations,
      generatedAt: new Date().toISOString()
    }));
  }

  private async cleanExpiredCache(): Promise<void> {
    const keys = await redis.keys('temp:*');
    if (keys.length > 0) {
      await redis.del(...keys);
      logger.info(`üßπ ${keys.length} chaves de cache tempor√°rio removidas`);
    }
  }

  private async performWeeklyBackup(): Promise<void> {
    const weekStart = format(startOfWeek(new Date()), 'yyyy-MM-dd');
    const weekEnd = format(endOfWeek(new Date()), 'yyyy-MM-dd');

    // Backup b√°sico de metadados (em produ√ß√£o seria um backup real)
    const tables = ['events', 'members', 'donations', 'ministries'];
    const backupData: any = {};

    for (const table of tables) {
      const { data, error } = await supabase
        .from(table)
        .select('id, created_at, updated_at')
        .gte('updated_at', weekStart)
        .lte('updated_at', weekEnd);

      if (!error && data) {
        backupData[table] = data.length;
      }
    }

    logger.info(`üíæ Backup semanal: ${JSON.stringify(backupData)}`);
    
    // Salvar metadados do backup
    await redis.setex(`backup:${weekStart}`, 86400 * 30, JSON.stringify({
      week: `${weekStart} to ${weekEnd}`,
      tables: backupData,
      backedUpAt: new Date().toISOString()
    }));
  }

  private async cleanOldLogs(): Promise<void> {
    // Em produ√ß√£o, aqui limparia arquivos de log antigos
    logger.info('üóÇÔ∏è Limpeza de logs executada (simulada)');
  }

  private async healthCheck(): Promise<void> {
    try {
      // Verificar conex√£o com Supabase
      const { error } = await supabase.from('users').select('id').limit(1);
      if (error) throw error;

      // Verificar conex√£o com Redis
      await redis.ping();

      // Criar arquivo de health check para Docker
      require('fs').writeFileSync('/tmp/worker-health', new Date().toISOString());
      
    } catch (error) {
      logger.error('‚ùå Health check falhou:', error);
      throw error;
    }
  }

  private async checkBirthdays(): Promise<void> {
    const today = format(new Date(), 'MM-dd');
    
    const { data: members, error } = await supabase
      .from('members')
      .select('id, name, birth_date, email')
      .like('birth_date', `%-${today}`);

    if (error) {
      logger.error('Erro ao buscar aniversariantes:', error);
      return;
    }

    if (members && members.length > 0) {
      logger.info(`üéÇ ${members.length} aniversariante(s) hoje: ${members.map(m => m.name).join(', ')}`);
      
      // Salvar lista de aniversariantes no cache
      await redis.setex(`birthdays:${format(new Date(), 'yyyy-MM-dd')}`, 86400, JSON.stringify(members));
    }
  }

  private async syncData(): Promise<void> {
    // Sincronizar contadores e estat√≠sticas
    const { data: eventCount } = await supabase
      .from('events')
      .select('id', { count: 'exact' });

    const { data: memberCount } = await supabase
      .from('members')
      .select('id', { count: 'exact' });

    const { data: ministryCount } = await supabase
      .from('ministries')
      .select('id', { count: 'exact' });

    const stats = {
      events: eventCount?.length || 0,
      members: memberCount?.length || 0,
      ministries: ministryCount?.length || 0,
      lastSync: new Date().toISOString()
    };

    await redis.setex('app:stats', 3600, JSON.stringify(stats));
    logger.info(`üîÑ Estat√≠sticas sincronizadas: ${JSON.stringify(stats)}`);
  }

  private setupGracefulShutdown(): void {
    const shutdown = (signal: string) => {
      logger.info(`Worker recebeu ${signal}, finalizando graciosamente...`);
      this.isRunning = false;
      
      setTimeout(() => {
        logger.info('Worker finalizado');
        process.exit(0);
      }, 1000);
    };

    process.on('SIGTERM', () => shutdown('SIGTERM'));
    process.on('SIGINT', () => shutdown('SIGINT'));
    process.on('SIGUSR2', () => shutdown('SIGUSR2')); // Para ts-node-dev
  }

  stop(): void {
    this.isRunning = false;
    logger.info('Worker parado');
  }
}